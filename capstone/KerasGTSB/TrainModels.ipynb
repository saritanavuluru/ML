{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#TODO : REFACTOR\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import sklearn\n",
    "import os\n",
    "from imp import reload\n",
    "#import helper\n",
    "import keras\n",
    "import pickle\n",
    "import math\n",
    "import collections\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.callbacks import CSVLogger, LearningRateScheduler,Callback,ModelCheckpoint,EarlyStopping,TensorBoard,ReduceLROnPlateau\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers.advanced_activations import LeakyReLU \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage import exposure\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten,Lambda\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Conv2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import statistics\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import random\n",
    "import csv\n",
    "from tensorflow.contrib.layers import flatten\n",
    "from skimage import transform as transf\n",
    "\n",
    "import loader\n",
    "import preprocess\n",
    "import plotter\n",
    "import Models\n",
    "\n",
    "#from prettytable import PrettyTable\n",
    "%matplotlib inline\n",
    "\n",
    "SEED = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "X_train: (34799, 32, 32, 3)\n",
      "X_test: (12630, 32, 32, 3)\n",
      "X_valid: (4410, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, y_train_orig, X_test_orig, y_test_orig,X_val_orig,y_val_orig = loader.load_split_input_data()\n",
    "\n",
    "#Models.print_model_architectures()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train RGB shape: (34799, 32, 32, 3)\n",
      "X_train Grayscale shape: (34799, 32, 32, 1)\n",
      "Transformation : Histogram Equalization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/skimage/exposure/exposure.py:63: UserWarning: This might be a color image. The histogram will be computed on the flattened image. You can instead apply this function to each color channel.\n",
      "  warn(\"This might be a color image. The histogram will be \"\n",
      "  0%|          | 0/34799 [00:00<?, ?it/s]/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/skimage/util/dtype.py:110: UserWarning: Possible precision loss when converting from float64 to uint16\n",
      "  \"%s to %s\" % (dtypeobj_in, dtypeobj))\n",
      "  0%|          | 6/34799 [00:00<10:47, 53.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation : Adaptive Equalization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34799/34799 [10:46<00:00, 53.79it/s]\n",
      "100%|██████████| 12630/12630 [03:52<00:00, 54.13it/s]\n",
      "100%|██████████| 4410/4410 [01:21<00:00, 53.97it/s]\n",
      "  2%|▏         | 559/34799 [00:00<00:06, 5585.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation : Contrast-Stretching\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34799/34799 [00:06<00:00, 5483.35it/s]\n",
      "100%|██████████| 12630/12630 [00:02<00:00, 5624.95it/s]\n",
      "100%|██████████| 4410/4410 [00:00<00:00, 5594.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combining dataset 0 of type <class 'numpy.ndarray'> and length 34799\n",
      "combining dataset 1 of type <class 'numpy.ndarray'> and length 34799\n",
      "combining dataset 2 of type <class 'numpy.ndarray'> and length 34799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/43 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of combined set : 104397\n",
      "Generating 1000 number of images per class, selecting 200 number of images per class for  augmentation\n",
      "Augmenting  Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:27<00:00,  2.21it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shufle\n",
      "X_augmented shape: (8600, 32, 32, 1)\n",
      "y_augmented shape: (8600,)\n",
      "Generating 5000 number of images per class, selecting 400 number of images per class for  augmentation\n",
      "No of classes:8\n",
      "classes:[7, 11, 15, 18, 22, 30, 35, 42]\n",
      "Augmenting  Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:12,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shufle\n",
      "X_augmented shape: (3200, 32, 32, 1)\n",
      "y_augmented shape: (3200,)\n",
      "preprocessed/preprocessed_gray_gray.p\n",
      "Saving data to preprocessed/preprocessed_gray_gray.p file...\n",
      "Data cached in preprocessed/preprocessed_gray_gray.p\n",
      "[41 41 41 ..., 25 25 25]\n",
      "preprocessed/preprocessed_hist_gray.p\n",
      "Saving data to preprocessed/preprocessed_hist_gray.p file...\n",
      "Data cached in preprocessed/preprocessed_hist_gray.p\n",
      "[41 41 41 ..., 25 25 25]\n",
      "preprocessed/preprocessed_hae_gray.p\n",
      "Saving data to preprocessed/preprocessed_hae_gray.p file...\n",
      "Data cached in preprocessed/preprocessed_hae_gray.p\n",
      "preprocessed/preprocessed_hcs_gray.p\n",
      "Saving data to preprocessed/preprocessed_hcs_gray.p file...\n",
      "Data cached in preprocessed/preprocessed_hcs_gray.p\n",
      "preprocessed_hset_aug_gray.p\n",
      "Saving data topreprocessed_hset_aug_gray.p file...\n",
      "Data cached in pickle file.\n",
      "combining dataset 0 of type <class 'numpy.ndarray'> and length 8600\n",
      "combining dataset 1 of type <class 'numpy.ndarray'> and length 104397\n",
      "combining dataset 2 of type <class 'numpy.ndarray'> and length 3200\n",
      "length of combined set : 116197\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train,X_test,y_test,X_val,y_val= preprocess.preprocess_aug_combine_save(X_train_orig,y_train_orig,X_test_orig,y_test_orig,X_val_orig,y_val_orig)\n",
    "\n",
    "#clear unused variables\n",
    "del X_train_orig\n",
    "del y_train_orig\n",
    "del X_test_orig\n",
    "del y_test_orig\n",
    "del X_val_orig\n",
    "del y_val_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./preprocessed/preprocessed_hset_aug_gray.p\n",
      "X_aug_all:  8600\n",
      "y_aug_all:  8600\n",
      "Data and modules loaded.\n",
      "./preprocessed/preprocessed_hist_gray.p\n",
      "X_train:  34799\n",
      "y_train:  34799\n",
      "X_val:  4410\n",
      "y_val:  4410\n",
      "X_test:  12630\n",
      "y_test:  12630\n",
      "Data and modules loaded.\n",
      "./preprocessed/preprocessed_hae_gray.p\n",
      "X_train:  34799\n",
      "y_train:  34799\n",
      "X_val:  4410\n",
      "y_val:  4410\n",
      "X_test:  12630\n",
      "y_test:  12630\n",
      "Data and modules loaded.\n",
      "./preprocessed/preprocessed_hcs_gray.p\n",
      "X_train:  34799\n",
      "y_train:  34799\n",
      "X_val:  4410\n",
      "y_val:  4410\n",
      "X_test:  12630\n",
      "y_test:  12630\n",
      "Data and modules loaded.\n",
      "combining dataset 0 of type <class 'numpy.ndarray'> and length 8600\n",
      "combining dataset 1 of type <class 'numpy.ndarray'> and length 34799\n",
      "combining dataset 2 of type <class 'numpy.ndarray'> and length 34799\n",
      "combining dataset 3 of type <class 'numpy.ndarray'> and length 34799\n",
      "length of combined set : 112997\n"
     ]
    }
   ],
   "source": [
    "#loader = reload(loader)\n",
    "#preprocess = reload(preprocess)\n",
    "X_train,y_train,X_test,y_test,X_val,y_val=loader.load_combine_preprocessed(\"hae\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_aug_classes, y_aug_classes = preprocess.data_augment_classes(y_hset,[7,11,15,18,22,30,35,42],n_gen_per_class=5000,n_aug_per_class=400)\n",
    "\n",
    "#X_train,y_train=preprocess.combine_datasets([(X_train,y_train),(X_aug_classes,y_aug_classes)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when using the categorical_crossentropy loss, the targets should be in categorical format (e.g. if you have 10 classes, the target for each sample should be a 10-dimensional vector that is all-zeros expect for a 1 at the index corresponding to the class of the sample). In order to convert integer targets into categorical targets, we can use the Keras utility to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#one hot  encoding of y series\n",
    "import params\n",
    "params = reload(params)\n",
    "y_train_e= np_utils.to_categorical(y_train,num_classes=params.n_classes)\n",
    "y_val_e = np_utils.to_categorical(y_val,num_classes=params.n_classes)\n",
    "y_test_e = np_utils.to_categorical(y_test,num_classes=params.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model_history(label,history) :\n",
    "    suffix='.log'\n",
    "    \n",
    "    filename = os.path.join(params.model_dir,'history_'+label+suffix)\n",
    "    \n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(history, f)\n",
    "    print(\"History saved in file \"+filename)\n",
    "    \n",
    "\n",
    "import tensorflow as tf\n",
    "class LearningRateTracker(Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "            \n",
    "        # _lr = K.get_value(tf.to_float(model.optimizer.lr, name='ToFloat'))\n",
    "        # _decay = tf.to_float(model.optimizer.decay, name='ToFloat')\n",
    "        #_iter = tf.to_float(model.optimizer.iterations, name='ToFloat')\n",
    "        \n",
    "        lr = K.get_value(model.optimizer.lr)\n",
    "        \n",
    "        print(\"\\nCurrent learning rate: \"+str(lr))\n",
    "\n",
    "                    \n",
    "def train_model(model,label,flag_earlystop=True,flag_reduceLR=True, flag_lrsched=False,flag_tensorboard=True):\n",
    " \n",
    "    # Compile and train the model\n",
    "    suffix = '.hdf5'\n",
    "    weights_file = os.path.join(params.model_dir,'weights_'+label+suffix)\n",
    "    print(weights_file)\n",
    "    \n",
    "    adam = Adam()\n",
    "    callbacks=[]\n",
    "    if (flag_tensorboard==True):\n",
    "        tensorboard=TensorBoard(log_dir=params.model_dir, histogram_freq=0, batch_size=512, write_graph=True)\n",
    "        callbacks.append(tensorboard)\n",
    "\n",
    "    if (flag_earlystop == True):\n",
    "        early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=4, verbose=2, mode='auto')\n",
    "        callbacks.append(early_stop)\n",
    "        \n",
    "    if (flag_reduceLR == True):\n",
    "        flag_lrsched=False\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,patience=4, min_lr=0.000001)\n",
    "        callbacks.append(reduce_lr)\n",
    "\n",
    "    #lr =  K.get_value(model.optimizer.lr)\n",
    "    \n",
    "    #lr = 0.0001\n",
    "    if (flag_lrsched == True):\n",
    "        lr = 0.01\n",
    "        adam=Adam(lr=lr)\n",
    "        def lr_schedule(epoch):\n",
    "            #print(\"-----------------------------epoch : \"+str(epoch))\n",
    "            #print(0.1 ** int(epoch / 10))\n",
    "            return lr * (0.1 ** int(epoch / 4))\n",
    "\n",
    "        lr_sched = LearningRateScheduler(lr_schedule)\n",
    "        callbacks.append(lr_sched)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=adam,\n",
    "          metrics=['accuracy'])\n",
    "    print(\"starting LR:\"+str(K.get_value(model.optimizer.lr)))\n",
    "    trackLR = LearningRateTracker()\n",
    "    \n",
    "    csv_logger = CSVLogger(params.model_dir+'/training.log', append=False)\n",
    "    checkpointer = ModelCheckpoint(filepath=weights_file, verbose=2, save_best_only=True, save_weights_only=True)\n",
    "    callbacks.append(csv_logger)\n",
    "    callbacks.append(checkpointer)\n",
    "    callbacks.append(trackLR)\n",
    "    \n",
    "    print(\"CALLBACKS : \"+str(callbacks))\n",
    "    try:\n",
    "\n",
    "        history = model.fit(X_train[:10], y_train_e[:10],\n",
    "                    batch_size=5, epochs=1,\n",
    "                    #callbacks=[checkpointer,early_stop,lr_sched],\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=1, validation_data=(X_val[:10], y_val_e[:10]))\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"training interrupted\")\n",
    "\n",
    "    evaluate = model.evaluate(X_test[:10],y_test_e[:10])\n",
    "    print(\"---------------------------------------\")\n",
    "    print(evaluate)\n",
    "    save_model_history(label,history.history)\n",
    "\n",
    "    return  history.history, evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.models.Sequential object at 0x0000015A7FAF9C88>\n",
      "model\\weights_BN_STN.hdf5\n",
      "starting LR:0.01\n",
      "CALLBACKS : [<keras.callbacks.TensorBoard object at 0x0000015A5FA350F0>, <keras.callbacks.EarlyStopping object at 0x0000015A5FA35CC0>, <keras.callbacks.LearningRateScheduler object at 0x0000015A7FAF96D8>, <keras.callbacks.CSVLogger object at 0x0000015A5FCC7940>, <keras.callbacks.ModelCheckpoint object at 0x0000015A5FADACC0>, <__main__.LearningRateTracker object at 0x0000015A5FB037F0>]\n",
      "Train on 10 samples, validate on 10 samples\n",
      "Epoch 1/1\n",
      " 5/10 [==============>...............] - ETA: 0s - loss: 5.5102 - acc: 0.0000e+00Epoch 00000: val_loss improved from inf to 5.05617, saving model to model\\weights_BN_STN.hdf5\n",
      "\n",
      "Current learning rate: 0.01\n",
      "10/10 [==============================] - 2s - loss: 4.4619 - acc: 0.0000e+00 - val_loss: 5.0562 - val_acc: 0.0000e+00\n",
      "10/10 [==============================] - 0s\n",
      "---------------------------------------\n",
      "[5.6602134704589844, 0.0]\n",
      "History saved in file model\\history_BN_STN.log\n"
     ]
    }
   ],
   "source": [
    "model = Models.deep_cnn_model(flag_BN=True,flag_STN=True)\n",
    "history,evaluate= train_model(model,\"BN_STN\",flag_earlystop=True,flag_reduceLR=False, flag_lrsched=True,flag_tensorboard=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.models.Sequential object at 0x7fe050e72a90>\n",
      "Train on 116197 samples, validate on 4410 samples\n",
      "Epoch 1/10\n",
      "115712/116197 [============================>.] - ETA: 0s - loss: 1.0041 - acc: 0.7187Epoch 00000: val_loss improved from inf to 2.63452, saving model to weights_default_lr_deeper_deep_no_stn.hdf5\n",
      "116197/116197 [==============================] - 82s - loss: 1.0014 - acc: 0.7195 - val_loss: 2.6345 - val_acc: 0.1376\n",
      "Epoch 2/10\n",
      "115712/116197 [============================>.] - ETA: 0s - loss: 0.1923 - acc: 0.9432Epoch 00001: val_loss improved from 2.63452 to 0.15629, saving model to weights_default_lr_deeper_deep_no_stn.hdf5\n",
      "116197/116197 [==============================] - 77s - loss: 0.1921 - acc: 0.9433 - val_loss: 0.1563 - val_acc: 0.9497\n",
      "Epoch 3/10\n",
      "115712/116197 [============================>.] - ETA: 0s - loss: 0.1158 - acc: 0.9653Epoch 00002: val_loss improved from 0.15629 to 0.02934, saving model to weights_default_lr_deeper_deep_no_stn.hdf5\n",
      "116197/116197 [==============================] - 77s - loss: 0.1157 - acc: 0.9653 - val_loss: 0.0293 - val_acc: 0.9902\n",
      "Epoch 4/10\n",
      "115712/116197 [============================>.] - ETA: 0s - loss: 0.0816 - acc: 0.9754Epoch 00003: val_loss did not improve\n",
      "116197/116197 [==============================] - 77s - loss: 0.0816 - acc: 0.9754 - val_loss: 0.0377 - val_acc: 0.9896\n",
      "Epoch 5/10\n",
      "115712/116197 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9794Epoch 00004: val_loss did not improve\n",
      "116197/116197 [==============================] - 77s - loss: 0.0689 - acc: 0.9794 - val_loss: 0.0388 - val_acc: 0.9884\n",
      "Epoch 6/10\n",
      "115712/116197 [============================>.] - ETA: 0s - loss: 0.0589 - acc: 0.9815Epoch 00005: val_loss improved from 0.02934 to 0.02282, saving model to weights_default_lr_deeper_deep_no_stn.hdf5\n",
      "116197/116197 [==============================] - 77s - loss: 0.0588 - acc: 0.9816 - val_loss: 0.0228 - val_acc: 0.9930\n",
      "Epoch 7/10\n",
      "115712/116197 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9849Epoch 00006: val_loss improved from 0.02282 to 0.01985, saving model to weights_default_lr_deeper_deep_no_stn.hdf5\n",
      "116197/116197 [==============================] - 77s - loss: 0.0501 - acc: 0.9849 - val_loss: 0.0199 - val_acc: 0.9941\n",
      "Epoch 8/10\n",
      "115712/116197 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9862Epoch 00007: val_loss did not improve\n",
      "116197/116197 [==============================] - 77s - loss: 0.0455 - acc: 0.9861 - val_loss: 0.0346 - val_acc: 0.9887\n",
      "Epoch 9/10\n",
      "115712/116197 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9881Epoch 00008: val_loss did not improve\n",
      "116197/116197 [==============================] - 77s - loss: 0.0400 - acc: 0.9881 - val_loss: 0.0445 - val_acc: 0.9880\n",
      "Epoch 10/10\n",
      "115712/116197 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9884Epoch 00009: val_loss did not improve\n",
      "116197/116197 [==============================] - 77s - loss: 0.0367 - acc: 0.9885 - val_loss: 0.0280 - val_acc: 0.9925\n"
     ]
    }
   ],
   "source": [
    "Models = reload(Models)\n",
    "model = Models.deep_cnn_model(flag_BN=True,flag_STN=True)\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath=\"weights_default_lr_deeper_deep_no_stn.hdf5\", verbose=2, save_best_only=True, save_weights_only=True)\n",
    "history = model.fit(X_train, y_train_e,\n",
    "                    batch_size=512, epochs=10,\n",
    "                    callbacks=[checkpointer],\n",
    "                    verbose=1, validation_data=(X_val, y_val_e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 116197 samples, validate on 4410 samples\n",
      "Epoch 1/10\n",
      "115712/116197 [============================>.] - ETA: 0s - loss: 1.3113 - acc: 0.6317Epoch 00000: val_loss improved from inf to 3.28081, saving model to weights_default_lr_deep_no_stn.hdf5\n",
      "116197/116197 [==============================] - 64s - loss: 1.3083 - acc: 0.6325 - val_loss: 3.2808 - val_acc: 0.1615\n",
      "Epoch 2/10\n",
      "115712/116197 [============================>.] - ETA: 0s - loss: 0.3629 - acc: 0.8894Epoch 00001: val_loss improved from 3.28081 to 0.38327, saving model to weights_default_lr_deep_no_stn.hdf5\n",
      "116197/116197 [==============================] - 59s - loss: 0.3628 - acc: 0.8895 - val_loss: 0.3833 - val_acc: 0.8766\n",
      "Epoch 3/10\n",
      "115712/116197 [============================>.] - ETA: 0s - loss: 0.2135 - acc: 0.9353Epoch 00002: val_loss improved from 0.38327 to 0.16401, saving model to weights_default_lr_deep_no_stn.hdf5\n",
      "116197/116197 [==============================] - 59s - loss: 0.2132 - acc: 0.9354 - val_loss: 0.1640 - val_acc: 0.9474\n",
      "Epoch 4/10\n",
      "115712/116197 [============================>.] - ETA: 0s - loss: 0.1516 - acc: 0.9533Epoch 00003: val_loss improved from 0.16401 to 0.06504, saving model to weights_default_lr_deep_no_stn.hdf5\n",
      "116197/116197 [==============================] - 59s - loss: 0.1515 - acc: 0.9534 - val_loss: 0.0650 - val_acc: 0.9798\n",
      "Epoch 5/10\n",
      "115712/116197 [============================>.] - ETA: 0s - loss: 0.1105 - acc: 0.9656Epoch 00004: val_loss improved from 0.06504 to 0.05109, saving model to weights_default_lr_deep_no_stn.hdf5\n",
      "116197/116197 [==============================] - 59s - loss: 0.1104 - acc: 0.9656 - val_loss: 0.0511 - val_acc: 0.9821\n",
      "Epoch 6/10\n",
      "115712/116197 [============================>.] - ETA: 0s - loss: 0.0872 - acc: 0.9731Epoch 00005: val_loss did not improve\n",
      "116197/116197 [==============================] - 59s - loss: 0.0872 - acc: 0.9731 - val_loss: 0.0581 - val_acc: 0.9785\n",
      "Epoch 7/10\n",
      "115712/116197 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9786Epoch 00006: val_loss improved from 0.05109 to 0.04628, saving model to weights_default_lr_deep_no_stn.hdf5\n",
      "116197/116197 [==============================] - 59s - loss: 0.0698 - acc: 0.9786 - val_loss: 0.0463 - val_acc: 0.9839\n",
      "Epoch 8/10\n",
      "115712/116197 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9814Epoch 00007: val_loss did not improve\n",
      "116197/116197 [==============================] - 59s - loss: 0.0584 - acc: 0.9814 - val_loss: 0.0468 - val_acc: 0.9850\n",
      "Epoch 9/10\n",
      "115712/116197 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9836Epoch 00008: val_loss improved from 0.04628 to 0.03950, saving model to weights_default_lr_deep_no_stn.hdf5\n",
      "116197/116197 [==============================] - 59s - loss: 0.0509 - acc: 0.9836 - val_loss: 0.0395 - val_acc: 0.9884\n",
      "Epoch 10/10\n",
      "115712/116197 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9859Epoch 00009: val_loss did not improve\n",
      "116197/116197 [==============================] - 59s - loss: 0.0445 - acc: 0.9859 - val_loss: 0.0620 - val_acc: 0.9828\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Models.deep_cnn_model(flag_BN=True,flag_STN=False)\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath=\"weights_default_lr_deep_no_stn.hdf5\", verbose=2, save_best_only=True, save_weights_only=True)\n",
    "history = model.fit(X_train, y_train_e,\n",
    "                    batch_size=512, epochs=10,\n",
    "                    callbacks=[checkpointer],\n",
    "                    verbose=1, validation_data=(X_val, y_val_e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12576/12630 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "e = model.evaluate(X_test,y_test_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.089369498425299648, 0.97593032462391127]\n"
     ]
    }
   ],
   "source": [
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEWCAYAAABBvWFzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMTOzTDihmJlZJpxQzMwsE04oZmaWif8PaAg1/mlflY4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15a90a4df60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_history=history\n",
    "plt.figure(1)  \n",
    "plt.subplot(211)  \n",
    "plt.plot(model_history['acc'])  \n",
    "plt.plot(model_history['val_acc'])  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left')  \n",
    "   \n",
    " # summarize history for loss  \n",
    "   \n",
    "plt.subplot(212)  \n",
    "plt.plot(model_history['loss'])  \n",
    "plt.plot(model_history['val_loss'])  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'validation'], loc='upper left')  \n",
    "plt.show()  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "tf_a",
   "language": "python",
   "name": "tf_a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
