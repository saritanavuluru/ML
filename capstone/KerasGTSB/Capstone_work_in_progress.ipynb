{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import sklearn\n",
    "import os\n",
    "\n",
    "import keras\n",
    "import pickle\n",
    "\n",
    "from keras.layers.advanced_activations import LeakyReLU \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Conv2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import pandas as pd\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "\n",
    "def load_split_input_data() :\n",
    "\n",
    "    # TODO: fill this in based on where you saved the training and testing data\n",
    "    training_file = './train.p'\n",
    "    testing_file = './test.p'\n",
    "    validation_file = './valid.p'\n",
    "\n",
    "\n",
    "    with open(training_file, mode='rb') as f:\n",
    "        train = pickle.load(f)\n",
    "    with open(testing_file, mode='rb') as f:\n",
    "        test = pickle.load(f)\n",
    "    with open(validation_file, mode='rb') as f:\n",
    "        valid = pickle.load(f)\n",
    "\n",
    "    X_train, y_train = train['features'], train['labels']\n",
    "    X_test, y_test = test['features'], test['labels']\n",
    "    X_val, y_val = valid['features'], valid['labels']\n",
    "\n",
    "    print(len(X_train))\n",
    "    print(len(X_test))\n",
    "    print(len(X_val))\n",
    "    print(len(y_val))\n",
    "\n",
    "    # STOP: Do not change the tests below. Your implementation should pass these tests. \n",
    "    assert(X_train.shape[0] == y_train.shape[0]), \"The number of images is not equal to the number of labels.\"\n",
    "    assert(X_test.shape[0] == y_test.shape[0]), \"The number of images is not equal to the number of labels.\"\n",
    "    assert(X_val.shape[0] == y_val.shape[0]), \"The number of images is not equal to the number of labels.\"\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, X_val, y_val\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#greyscale\n",
    "# Convert to grayscale\n",
    "\n",
    "def convert_to_grayscale(X_train,X_test, X_val):\n",
    "\n",
    "    X_train_rgb = X_train\n",
    "    X_val_rgb = X_val\n",
    "    X_train_gry = np.sum(X_train/3, \n",
    "                     axis=3, keepdims=True)\n",
    "\n",
    "    X_test_rgb = X_test\n",
    "    X_test_gry = np.sum(X_test/3, axis=3, keepdims=True)\n",
    "    X_val_gry = np.sum(X_val/3, axis=3, keepdims=True)\n",
    "    \n",
    "    print('RGB shape:', X_train_rgb.shape)\n",
    "    print('Grayscale shape:', X_train_gry.shape)\n",
    "    X_train = X_train_gry\n",
    "    X_test = X_test_gry\n",
    "    X_val = X_val_gry\n",
    "    \n",
    "    assert(X_train.shape[1:] == (32,32,1)), \"The dimensions of the images are not 32 x 32 x 1.\"\n",
    "    return X_train,X_test, X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(X_train, y_train, X_test, y_test, X_val, y_val):\n",
    "\n",
    "    X_train, X_test , X_val = convert_to_grayscale(X_train, X_test, X_val)\n",
    "    \n",
    "    # Shuffle data\n",
    "    X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "    X_test, y_test = shuffle(X_test, y_test, random_state=42)\n",
    "    X_val, y_val = shuffle(X_val, y_val, random_state = 42)\n",
    "    \n",
    "    # Normalise data\n",
    "    X_train = (X_train - X_train.mean()) / (np.max(X_train) - np.min(X_train))\n",
    "    X_test = (X_test - X_test.mean()) / (np.max(X_test) - np.min(X_test))\n",
    "    X_val = (X_val - X_val.mean())/(np.max(X_val)-np.min(X_val))\n",
    "    # One-hot encode labels\n",
    "    y_train = np_utils.to_categorical(y_train,num_classes=43)\n",
    "    y_test = np_utils.to_categorical(y_test, num_classes=43)\n",
    "    y_val = np_utils.to_categorical(y_val, num_classes=43)\n",
    "\n",
    "    \n",
    "\n",
    "    print(\"X_train: \", len(X_train))\n",
    "    print(\"y_train: \", len(y_train))\n",
    "    print(\"X_val: \", len(X_val))\n",
    "    print(\"y_val: \", len(y_val))\n",
    "    return X_train, y_train, X_test, y_test, X_val, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34799\n",
      "12630\n",
      "4410\n",
      "4410\n",
      "RGB shape: (34799, 32, 32, 3)\n",
      "Grayscale shape: (34799, 32, 32, 1)\n",
      "RGB shape: (34799, 32, 32, 1)\n",
      "Grayscale shape: (34799, 32, 32, 1)\n",
      "X_train:  34799\n",
      "y_train:  34799\n",
      "X_val:  4410\n",
      "y_val:  4410\n",
      "34799\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test,X_val,y_val = load_split_input_data()\n",
    "X_train, X_test,X_val = convert_to_grayscale(X_train, X_test,X_val)\n",
    "X_train, y_train, X_test, y_test, X_val,y_val = preprocess_data(X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to pickle file...\n",
      "Data cached in pickle file.\n"
     ]
    }
   ],
   "source": [
    "# Save the data for easy access\n",
    "\n",
    "pickle_file = 'preprocessed_data.p'\n",
    "if not os.path.isfile(pickle_file):\n",
    "    print('Saving data to pickle file...')\n",
    "    try:\n",
    "        with open(pickle_file, 'wb') as pfile:\n",
    "            pickle.dump(\n",
    "                {\n",
    "                    'y_train': y_train,\n",
    "                    'X_train': X_train,\n",
    "                    'X_val': X_val,\n",
    "                    'y_val': y_val,\n",
    "                    'X_test': X_test,\n",
    "                    'y_test': y_test\n",
    "                },\n",
    "                pfile, pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as e:\n",
    "        print('Unable to save data to', pickle_file, ':', e)\n",
    "        raise\n",
    "\n",
    "print('Data cached in pickle file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed_data.p\n",
      "34799\n",
      "X_train:  34799\n",
      "y_train:  34799\n",
      "X_val:  4410\n",
      "y_val:  4410\n",
      "X_test:  12630\n",
      "y_test:  12630\n",
      "Data and modules loaded.\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import os\n",
    "\n",
    "import keras\n",
    "import pickle\n",
    "pickle_file = 'preprocessed_data.p'\n",
    "\n",
    "# Reload the data\n",
    "print(pickle_file)\n",
    "with open(pickle_file, 'rb') as f:\n",
    "      pickle_data = pickle.load(f)\n",
    "      X_train = pickle_data['X_train']\n",
    "      print(len(X_train))\n",
    "      y_train = pickle_data['y_train']\n",
    "      X_val = pickle_data['X_val']\n",
    "      y_val = pickle_data['y_val']\n",
    "      X_test = pickle_data['X_test']\n",
    "      y_test = pickle_data['y_test']\n",
    "      del pickle_data  # Free up memory\n",
    "      print(\"X_train: \", len(X_train))\n",
    "      print(\"y_train: \", len(y_train))\n",
    "      print(\"X_val: \", len(X_val))\n",
    "      print(\"y_val: \", len(y_val))\n",
    "      print(\"X_test: \", len(X_test))\n",
    "      print(\"y_test: \", len(y_test))\n",
    "\n",
    "      print('Data and modules loaded.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPATIAL TRANSFORMER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Layer\n",
    "import tensorflow as tf\n",
    "\n",
    "class SpatialTransformer(Layer):\n",
    "    \"\"\"Spatial Transformer Layer\n",
    "    Implements a spatial transformer layer as described in [1]_.\n",
    "    Borrowed from [2]_:\n",
    "    downsample_fator : float\n",
    "        A value of 1 will keep the orignal size of the image.\n",
    "        Values larger than 1 will down sample the image. Values below 1 will\n",
    "        upsample the image.\n",
    "        example image: height= 100, width = 200\n",
    "        downsample_factor = 2\n",
    "        output image will then be 50, 100\n",
    "    References\n",
    "    ----------\n",
    "    .. [1]  Spatial Transformer Networks\n",
    "            Max Jaderberg, Karen Simonyan, Andrew Zisserman, Koray Kavukcuoglu\n",
    "            Submitted on 5 Jun 2015\n",
    "    .. [2]  https://github.com/skaae/transformer_network/blob/master/transformerlayer.py\n",
    "    .. [3]  https://github.com/EderSantana/seya/blob/keras1/seya/layers/attention.py\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 localization_net,\n",
    "                 output_size,\n",
    "                 **kwargs):\n",
    "        self.locnet = localization_net\n",
    "        self.output_size = output_size\n",
    "        super(SpatialTransformer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.locnet.build(input_shape)\n",
    "        self.trainable_weights = self.locnet.trainable_weights\n",
    "        #self.regularizers = self.locnet.regularizers //NOT SUER ABOUT THIS, THERE IS NO MORE SUCH PARAMETR AT self.locnet\n",
    "        #self.constraints = self.locnet.constraints\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_size = self.output_size\n",
    "        return (None,\n",
    "                int(output_size[0]),\n",
    "                int(output_size[1]),\n",
    "                int(input_shape[-1]))\n",
    "\n",
    "    def call(self, X, mask=None):\n",
    "        affine_transformation = self.locnet.call(X)\n",
    "        output = self._transform(affine_transformation, X, self.output_size)\n",
    "        return output\n",
    "\n",
    "    def _repeat(self, x, num_repeats):\n",
    "        ones = tf.ones((1, num_repeats), dtype='int32')\n",
    "        x = tf.reshape(x, shape=(-1,1))\n",
    "        x = tf.matmul(x, ones)\n",
    "        return tf.reshape(x, [-1])\n",
    "\n",
    "    def _interpolate(self, image, x, y, output_size):\n",
    "        batch_size = tf.shape(image)[0]\n",
    "        height = tf.shape(image)[1]\n",
    "        width = tf.shape(image)[2]\n",
    "        num_channels = tf.shape(image)[3]\n",
    "\n",
    "        x = tf.cast(x , dtype='float32')\n",
    "        y = tf.cast(y , dtype='float32')\n",
    "\n",
    "        height_float = tf.cast(height, dtype='float32')\n",
    "        width_float = tf.cast(width, dtype='float32')\n",
    "\n",
    "        output_height = output_size[0]\n",
    "        output_width  = output_size[1]\n",
    "\n",
    "        x = .5*(x + 1.0)*(width_float)\n",
    "        y = .5*(y + 1.0)*(height_float)\n",
    "\n",
    "        x0 = tf.cast(tf.floor(x), 'int32')\n",
    "        x1 = x0 + 1\n",
    "        y0 = tf.cast(tf.floor(y), 'int32')\n",
    "        y1 = y0 + 1\n",
    "\n",
    "        max_y = tf.cast(height - 1, dtype='int32')\n",
    "        max_x = tf.cast(width - 1,  dtype='int32')\n",
    "        zero = tf.zeros([], dtype='int32')\n",
    "\n",
    "        x0 = tf.clip_by_value(x0, zero, max_x)\n",
    "        x1 = tf.clip_by_value(x1, zero, max_x)\n",
    "        y0 = tf.clip_by_value(y0, zero, max_y)\n",
    "        y1 = tf.clip_by_value(y1, zero, max_y)\n",
    "\n",
    "        flat_image_dimensions = width*height\n",
    "        pixels_batch = tf.range(batch_size)*flat_image_dimensions\n",
    "        flat_output_dimensions = output_height*output_width\n",
    "        base = self._repeat(pixels_batch, flat_output_dimensions)\n",
    "        base_y0 = base + y0*width\n",
    "        base_y1 = base + y1*width\n",
    "        indices_a = base_y0 + x0\n",
    "        indices_b = base_y1 + x0\n",
    "        indices_c = base_y0 + x1\n",
    "        indices_d = base_y1 + x1\n",
    "\n",
    "        flat_image = tf.reshape(image, shape=(-1, num_channels))\n",
    "        flat_image = tf.cast(flat_image, dtype='float32')\n",
    "        pixel_values_a = tf.gather(flat_image, indices_a)\n",
    "        pixel_values_b = tf.gather(flat_image, indices_b)\n",
    "        pixel_values_c = tf.gather(flat_image, indices_c)\n",
    "        pixel_values_d = tf.gather(flat_image, indices_d)\n",
    "\n",
    "        x0 = tf.cast(x0, 'float32')\n",
    "        x1 = tf.cast(x1, 'float32')\n",
    "        y0 = tf.cast(y0, 'float32')\n",
    "        y1 = tf.cast(y1, 'float32')\n",
    "\n",
    "        area_a = tf.expand_dims(((x1 - x) * (y1 - y)), 1)\n",
    "        area_b = tf.expand_dims(((x1 - x) * (y - y0)), 1)\n",
    "        area_c = tf.expand_dims(((x - x0) * (y1 - y)), 1)\n",
    "        area_d = tf.expand_dims(((x - x0) * (y - y0)), 1)\n",
    "        output = tf.add_n([area_a*pixel_values_a,\n",
    "                           area_b*pixel_values_b,\n",
    "                           area_c*pixel_values_c,\n",
    "                           area_d*pixel_values_d])\n",
    "        return output\n",
    "\n",
    "    def _meshgrid(self, height, width):\n",
    "        x_linspace = tf.linspace(-1., 1., width)\n",
    "        y_linspace = tf.linspace(-1., 1., height)\n",
    "        x_coordinates, y_coordinates = tf.meshgrid(x_linspace, y_linspace)\n",
    "        x_coordinates = tf.reshape(x_coordinates, [-1])\n",
    "        y_coordinates = tf.reshape(y_coordinates, [-1])\n",
    "        ones = tf.ones_like(x_coordinates)\n",
    "        indices_grid = tf.concat([x_coordinates, y_coordinates, ones], 0)\n",
    "        return indices_grid\n",
    "\n",
    "    def _transform(self, affine_transformation, input_shape, output_size):\n",
    "        batch_size = tf.shape(input_shape)[0]\n",
    "        height = tf.shape(input_shape)[1]\n",
    "        width = tf.shape(input_shape)[2]\n",
    "        num_channels = tf.shape(input_shape)[3]\n",
    "\n",
    "        affine_transformation = tf.reshape(affine_transformation, shape=(batch_size,2,3))\n",
    "\n",
    "        affine_transformation = tf.reshape(affine_transformation, (-1, 2, 3))\n",
    "        affine_transformation = tf.cast(affine_transformation, 'float32')\n",
    "\n",
    "        width = tf.cast(width, dtype='float32')\n",
    "        height = tf.cast(height, dtype='float32')\n",
    "        output_height = output_size[0]\n",
    "        output_width = output_size[1]\n",
    "        indices_grid = self._meshgrid(output_height, output_width)\n",
    "        indices_grid = tf.expand_dims(indices_grid, 0)\n",
    "        indices_grid = tf.reshape(indices_grid, [-1]) # flatten?\n",
    "\n",
    "        indices_grid = tf.tile(indices_grid, tf.stack([batch_size]))\n",
    "        indices_grid = tf.reshape(indices_grid, (batch_size, 3, -1))\n",
    "\n",
    "        transformed_grid = tf.matmul(affine_transformation, indices_grid)\n",
    "        x_s = tf.slice(transformed_grid, [0, 0, 0], [-1, 1, -1])\n",
    "        y_s = tf.slice(transformed_grid, [0, 1, 0], [-1, 1, -1])\n",
    "        x_s_flatten = tf.reshape(x_s, [-1])\n",
    "        y_s_flatten = tf.reshape(y_s, [-1])\n",
    "\n",
    "        transformed_image = self._interpolate(input_shape,\n",
    "                                                x_s_flatten,\n",
    "                                                y_s_flatten,\n",
    "                                                output_size)\n",
    "\n",
    "        transformed_image = tf.reshape(transformed_image, shape=(batch_size,\n",
    "                                                                output_height,\n",
    "                                                                output_width,\n",
    "                                                                num_channels))\n",
    "        return transformed_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOCNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def locnet():\n",
    "\n",
    "    # initial weights\n",
    "    b = np.zeros((2, 3), dtype='float32')\n",
    "    b[0, 0] = 1\n",
    "    b[1, 1] = 1\n",
    "    W = np.zeros((50, 6), dtype='float32')\n",
    "    weights = [W, b.flatten()]\n",
    "\n",
    "    input_shape = (32,32,1)\n",
    "\n",
    "    #locnet\n",
    "    locnet = Sequential()\n",
    "    locnet.add(MaxPooling2D(pool_size=(2,2), input_shape=input_shape))\n",
    "    locnet.add(Conv2D(20, (5, 5)))\n",
    "    locnet.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    locnet.add(Conv2D(20, (5, 5)))\n",
    "\n",
    "    locnet.add(Flatten())\n",
    "    locnet.add(Dense(50))\n",
    "    model.add(LeakyReLU(alpha=0.5))\n",
    "    locnet.add(Dense(6, weights=weights))\n",
    "    return locnet\n",
    "    #locnet.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  CNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cnn_model(flag_BN=False, flag_STN=False):\n",
    "\n",
    "    \n",
    "    model = Sequential()\n",
    "    if flag_STN == True:\n",
    "        lnet = locnet()\n",
    "        print(lnet)\n",
    "        model.add(SpatialTransformer(localization_net=lnet,\n",
    "                            input_shape=(32,32,1),output_size=(32,32)))\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=( 32, 32,1)))                    \n",
    "    #model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    if flag_BN == True:\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "    model.add(LeakyReLU(alpha=0.5))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "\n",
    "    #model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    if flag_BN == True:\n",
    "        model.add(BatchNormalization())  \n",
    "    model.add(LeakyReLU(alpha=0.5))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "    #model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    if flag_BN == True:\n",
    "        model.add(BatchNormalization())  \n",
    "    model.add(LeakyReLU(alpha=0.5))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    if flag_BN == True:\n",
    "        model.add(BatchNormalization())  \n",
    "    model.add(LeakyReLU(alpha=0.5))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(43, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN without Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_44 (Conv2D)           (None, 32, 32, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 43)                44075     \n",
      "=================================================================\n",
      "Total params: 2,234,923\n",
      "Trainable params: 2,234,923\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34799 samples, validate on 4410 samples\n",
      "Epoch 1/100\n",
      "34799/34799 [==============================] - 9s - loss: 3.2531 - acc: 0.1264 - val_loss: 2.8927 - val_acc: 0.2680\n",
      "Epoch 2/100\n",
      "34799/34799 [==============================] - 8s - loss: 1.7893 - acc: 0.4871 - val_loss: 1.2002 - val_acc: 0.6649\n",
      "Epoch 3/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.8590 - acc: 0.7335 - val_loss: 0.8307 - val_acc: 0.7630\n",
      "Epoch 4/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.5198 - acc: 0.8384 - val_loss: 0.6052 - val_acc: 0.8336\n",
      "Epoch 5/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.3612 - acc: 0.8862 - val_loss: 0.4929 - val_acc: 0.8635\n",
      "Epoch 6/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.2649 - acc: 0.9192 - val_loss: 0.4505 - val_acc: 0.8798\n",
      "Epoch 7/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.2093 - acc: 0.9355 - val_loss: 0.3649 - val_acc: 0.9000\n",
      "Epoch 8/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.1691 - acc: 0.9472 - val_loss: 0.3533 - val_acc: 0.8998\n",
      "Epoch 9/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.1374 - acc: 0.9582 - val_loss: 0.3118 - val_acc: 0.9215\n",
      "Epoch 10/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.1160 - acc: 0.9653 - val_loss: 0.2990 - val_acc: 0.9118\n",
      "Epoch 11/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.1037 - acc: 0.9682 - val_loss: 0.2957 - val_acc: 0.9281\n",
      "Epoch 12/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0911 - acc: 0.9730 - val_loss: 0.3139 - val_acc: 0.9256\n",
      "Epoch 13/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0801 - acc: 0.9757 - val_loss: 0.3167 - val_acc: 0.9202\n",
      "Epoch 14/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0702 - acc: 0.9778 - val_loss: 0.2967 - val_acc: 0.9166\n",
      "Epoch 15/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0652 - acc: 0.9806 - val_loss: 0.3172 - val_acc: 0.9322\n",
      "Epoch 16/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0574 - acc: 0.9826 - val_loss: 0.2795 - val_acc: 0.9370\n",
      "Epoch 17/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0507 - acc: 0.9848 - val_loss: 0.2952 - val_acc: 0.9265\n",
      "Epoch 18/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0502 - acc: 0.9845 - val_loss: 0.2854 - val_acc: 0.9338\n",
      "Epoch 19/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0479 - acc: 0.9856 - val_loss: 0.3144 - val_acc: 0.9238\n",
      "Epoch 20/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0430 - acc: 0.9872 - val_loss: 0.2621 - val_acc: 0.9413\n",
      "Epoch 21/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0394 - acc: 0.9888 - val_loss: 0.2991 - val_acc: 0.9374\n",
      "Epoch 22/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0355 - acc: 0.9892 - val_loss: 0.3089 - val_acc: 0.9315\n",
      "Epoch 23/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0339 - acc: 0.9897 - val_loss: 0.3097 - val_acc: 0.9358\n",
      "Epoch 24/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0306 - acc: 0.9914 - val_loss: 0.2885 - val_acc: 0.9410\n",
      "Epoch 25/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0287 - acc: 0.9918 - val_loss: 0.2861 - val_acc: 0.9345\n",
      "Epoch 26/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0287 - acc: 0.9917 - val_loss: 0.2972 - val_acc: 0.9399\n",
      "Epoch 27/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0285 - acc: 0.9915 - val_loss: 0.2668 - val_acc: 0.9372\n",
      "Epoch 28/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0261 - acc: 0.9920 - val_loss: 0.2340 - val_acc: 0.9510\n",
      "Epoch 29/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0254 - acc: 0.9924 - val_loss: 0.2840 - val_acc: 0.9465\n",
      "Epoch 30/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0234 - acc: 0.9931 - val_loss: 0.2550 - val_acc: 0.9483\n",
      "Epoch 31/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0239 - acc: 0.9929 - val_loss: 0.2899 - val_acc: 0.9465\n",
      "Epoch 32/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0232 - acc: 0.9926 - val_loss: 0.2280 - val_acc: 0.9540\n",
      "Epoch 33/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0209 - acc: 0.9938 - val_loss: 0.2735 - val_acc: 0.9438\n",
      "Epoch 34/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0220 - acc: 0.9936 - val_loss: 0.2727 - val_acc: 0.9478\n",
      "Epoch 35/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0176 - acc: 0.9949 - val_loss: 0.2565 - val_acc: 0.9510\n",
      "Epoch 36/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0176 - acc: 0.9946 - val_loss: 0.2555 - val_acc: 0.9485\n",
      "Epoch 37/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0184 - acc: 0.9948 - val_loss: 0.2849 - val_acc: 0.9438\n",
      "Epoch 38/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0172 - acc: 0.9950 - val_loss: 0.2498 - val_acc: 0.9474\n",
      "Epoch 39/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0167 - acc: 0.9948 - val_loss: 0.2902 - val_acc: 0.9456\n",
      "Epoch 40/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0193 - acc: 0.9948 - val_loss: 0.2607 - val_acc: 0.9501\n",
      "Epoch 41/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0157 - acc: 0.9954 - val_loss: 0.2809 - val_acc: 0.9508\n",
      "Epoch 42/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0157 - acc: 0.9953 - val_loss: 0.2548 - val_acc: 0.9488\n",
      "Epoch 43/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0137 - acc: 0.9957 - val_loss: 0.2771 - val_acc: 0.9540\n",
      "Epoch 44/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0138 - acc: 0.9958 - val_loss: 0.2411 - val_acc: 0.9599\n",
      "Epoch 45/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0153 - acc: 0.9957 - val_loss: 0.2790 - val_acc: 0.9467\n",
      "Epoch 46/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0129 - acc: 0.9963 - val_loss: 0.2571 - val_acc: 0.9553\n",
      "Epoch 47/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0129 - acc: 0.9961 - val_loss: 0.2755 - val_acc: 0.9515\n",
      "Epoch 48/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0128 - acc: 0.9961 - val_loss: 0.2459 - val_acc: 0.9580\n",
      "Epoch 49/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0145 - acc: 0.9955 - val_loss: 0.2644 - val_acc: 0.9537\n",
      "Epoch 50/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0130 - acc: 0.9959 - val_loss: 0.2856 - val_acc: 0.9442\n",
      "Epoch 51/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0121 - acc: 0.9965 - val_loss: 0.2569 - val_acc: 0.9560\n",
      "Epoch 52/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0117 - acc: 0.9965 - val_loss: 0.2648 - val_acc: 0.9535\n",
      "Epoch 53/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0123 - acc: 0.9965 - val_loss: 0.2875 - val_acc: 0.9465\n",
      "Epoch 54/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0142 - acc: 0.9957 - val_loss: 0.2645 - val_acc: 0.9533\n",
      "Epoch 55/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0116 - acc: 0.9964 - val_loss: 0.2608 - val_acc: 0.9556\n",
      "Epoch 56/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0097 - acc: 0.9967 - val_loss: 0.2721 - val_acc: 0.9558\n",
      "Epoch 57/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0108 - acc: 0.9967 - val_loss: 0.2475 - val_acc: 0.9587\n",
      "Epoch 58/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0122 - acc: 0.9960 - val_loss: 0.2772 - val_acc: 0.9492\n",
      "Epoch 59/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0111 - acc: 0.9968 - val_loss: 0.2822 - val_acc: 0.9494\n",
      "Epoch 60/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0119 - acc: 0.9962 - val_loss: 0.2414 - val_acc: 0.9605\n",
      "Epoch 61/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0102 - acc: 0.9972 - val_loss: 0.2803 - val_acc: 0.9458\n",
      "Epoch 62/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0085 - acc: 0.9977 - val_loss: 0.2858 - val_acc: 0.9519\n",
      "Epoch 63/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0099 - acc: 0.9966 - val_loss: 0.2406 - val_acc: 0.9599\n",
      "Epoch 64/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0114 - acc: 0.9965 - val_loss: 0.2643 - val_acc: 0.9546\n",
      "Epoch 65/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0089 - acc: 0.9974 - val_loss: 0.2545 - val_acc: 0.9571\n",
      "Epoch 66/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0101 - acc: 0.9972 - val_loss: 0.2657 - val_acc: 0.9556\n",
      "Epoch 67/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0099 - acc: 0.9968 - val_loss: 0.2253 - val_acc: 0.9653\n",
      "Epoch 68/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0113 - acc: 0.9966 - val_loss: 0.2478 - val_acc: 0.9506\n",
      "Epoch 69/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0084 - acc: 0.9976 - val_loss: 0.2630 - val_acc: 0.9571\n",
      "Epoch 70/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0096 - acc: 0.9973 - val_loss: 0.2518 - val_acc: 0.9601\n",
      "Epoch 71/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0098 - acc: 0.9972 - val_loss: 0.2682 - val_acc: 0.9528\n",
      "Epoch 72/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0076 - acc: 0.9978 - val_loss: 0.2937 - val_acc: 0.9460\n",
      "Epoch 73/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0094 - acc: 0.9971 - val_loss: 0.2596 - val_acc: 0.9590\n",
      "Epoch 74/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0083 - acc: 0.9974 - val_loss: 0.2759 - val_acc: 0.9551\n",
      "Epoch 75/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0077 - acc: 0.9976 - val_loss: 0.2837 - val_acc: 0.9492\n",
      "Epoch 76/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0072 - acc: 0.9977 - val_loss: 0.3034 - val_acc: 0.9483\n",
      "Epoch 77/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0091 - acc: 0.9973 - val_loss: 0.2792 - val_acc: 0.9544\n",
      "Epoch 78/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0099 - acc: 0.9969 - val_loss: 0.2684 - val_acc: 0.9571\n",
      "Epoch 79/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0098 - acc: 0.9971 - val_loss: 0.3112 - val_acc: 0.9447\n",
      "Epoch 80/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0085 - acc: 0.9972 - val_loss: 0.2933 - val_acc: 0.9526\n",
      "Epoch 81/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0081 - acc: 0.9970 - val_loss: 0.2644 - val_acc: 0.9571\n",
      "Epoch 82/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0089 - acc: 0.9974 - val_loss: 0.2523 - val_acc: 0.9553\n",
      "Epoch 83/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0078 - acc: 0.9976 - val_loss: 0.2561 - val_acc: 0.9578\n",
      "Epoch 84/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0073 - acc: 0.9977 - val_loss: 0.2923 - val_acc: 0.9501\n",
      "Epoch 85/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0071 - acc: 0.9978 - val_loss: 0.2692 - val_acc: 0.9537\n",
      "Epoch 86/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0067 - acc: 0.9978 - val_loss: 0.2637 - val_acc: 0.9522\n",
      "Epoch 87/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0083 - acc: 0.9973 - val_loss: 0.2730 - val_acc: 0.9544\n",
      "Epoch 88/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0084 - acc: 0.9974 - val_loss: 0.2675 - val_acc: 0.9585\n",
      "Epoch 89/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0075 - acc: 0.9977 - val_loss: 0.2653 - val_acc: 0.9576\n",
      "Epoch 90/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0096 - acc: 0.9971 - val_loss: 0.2578 - val_acc: 0.9590\n",
      "Epoch 91/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0066 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9628\n",
      "Epoch 92/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0081 - acc: 0.9975 - val_loss: 0.2150 - val_acc: 0.9728\n",
      "Epoch 93/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0084 - acc: 0.9974 - val_loss: 0.2389 - val_acc: 0.9655\n",
      "Epoch 94/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0077 - acc: 0.9975 - val_loss: 0.2300 - val_acc: 0.9703\n",
      "Epoch 95/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0101 - acc: 0.9967 - val_loss: 0.2579 - val_acc: 0.9515\n",
      "Epoch 96/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0076 - acc: 0.9977 - val_loss: 0.2529 - val_acc: 0.9610\n",
      "Epoch 97/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0066 - acc: 0.9977 - val_loss: 0.2407 - val_acc: 0.9594\n",
      "Epoch 98/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0052 - acc: 0.9985 - val_loss: 0.2558 - val_acc: 0.9610\n",
      "Epoch 99/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0080 - acc: 0.9978 - val_loss: 0.2404 - val_acc: 0.9644\n",
      "Epoch 100/100\n",
      "34799/34799 [==============================] - 8s - loss: 0.0081 - acc: 0.9977 - val_loss: 0.2707 - val_acc: 0.9571\n"
     ]
    }
   ],
   "source": [
    "model = cnn_model()\n",
    "# Compile and train the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512, nb_epoch=100,\n",
    "                    verbose=1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12352/12630 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30626305522325231, 0.94877276333758309]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('models/CNN.ckpt')\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN  with Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_41 (Conv2D)           (None, 32, 32, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 43)                44075     \n",
      "=================================================================\n",
      "Total params: 2,239,915\n",
      "Trainable params: 2,237,419\n",
      "Non-trainable params: 2,496\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34799 samples, validate on 4410 samples\n",
      "Epoch 1/100\n",
      "34799/34799 [==============================] - 15s - loss: 2.2176 - acc: 0.4106 - val_loss: 3.7137 - val_acc: 0.0982\n",
      "Epoch 2/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.6742 - acc: 0.7985 - val_loss: 4.1191 - val_acc: 0.1066\n",
      "Epoch 3/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.3450 - acc: 0.8964 - val_loss: 3.7261 - val_acc: 0.2134\n",
      "Epoch 4/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.2268 - acc: 0.9328 - val_loss: 2.9929 - val_acc: 0.2510\n",
      "Epoch 5/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.1692 - acc: 0.9515 - val_loss: 2.2415 - val_acc: 0.3635\n",
      "Epoch 6/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.1273 - acc: 0.9630 - val_loss: 1.3914 - val_acc: 0.5503\n",
      "Epoch 7/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.1021 - acc: 0.9700 - val_loss: 0.7103 - val_acc: 0.7828\n",
      "Epoch 8/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0833 - acc: 0.9760 - val_loss: 0.5244 - val_acc: 0.8356\n",
      "Epoch 9/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0688 - acc: 0.9796 - val_loss: 0.3072 - val_acc: 0.9138\n",
      "Epoch 10/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0607 - acc: 0.9810 - val_loss: 0.3546 - val_acc: 0.8993\n",
      "Epoch 11/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0510 - acc: 0.9857 - val_loss: 0.2649 - val_acc: 0.9229\n",
      "Epoch 12/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0464 - acc: 0.9867 - val_loss: 0.2270 - val_acc: 0.9320\n",
      "Epoch 13/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0419 - acc: 0.9874 - val_loss: 0.2972 - val_acc: 0.9061\n",
      "Epoch 14/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0337 - acc: 0.9909 - val_loss: 0.2488 - val_acc: 0.9265\n",
      "Epoch 15/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0323 - acc: 0.9907 - val_loss: 0.2547 - val_acc: 0.9227\n",
      "Epoch 16/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0285 - acc: 0.9917 - val_loss: 0.2552 - val_acc: 0.9229\n",
      "Epoch 17/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0267 - acc: 0.9922 - val_loss: 0.2540 - val_acc: 0.9229\n",
      "Epoch 18/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0236 - acc: 0.9933 - val_loss: 0.2057 - val_acc: 0.9363\n",
      "Epoch 19/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0219 - acc: 0.9936 - val_loss: 0.2034 - val_acc: 0.9374\n",
      "Epoch 20/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0192 - acc: 0.9948 - val_loss: 0.1676 - val_acc: 0.9540\n",
      "Epoch 21/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0181 - acc: 0.9947 - val_loss: 0.2802 - val_acc: 0.9288\n",
      "Epoch 22/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0168 - acc: 0.9952 - val_loss: 0.3950 - val_acc: 0.8921\n",
      "Epoch 23/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0150 - acc: 0.9958 - val_loss: 0.3386 - val_acc: 0.9086\n",
      "Epoch 24/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0165 - acc: 0.9949 - val_loss: 0.3997 - val_acc: 0.8921\n",
      "Epoch 25/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0143 - acc: 0.9959 - val_loss: 0.2485 - val_acc: 0.9229\n",
      "Epoch 26/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0146 - acc: 0.9958 - val_loss: 0.2088 - val_acc: 0.9374\n",
      "Epoch 27/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0130 - acc: 0.9962 - val_loss: 0.1669 - val_acc: 0.9519\n",
      "Epoch 28/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0120 - acc: 0.9964 - val_loss: 0.2096 - val_acc: 0.9281\n",
      "Epoch 29/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0127 - acc: 0.9963 - val_loss: 0.2734 - val_acc: 0.9161\n",
      "Epoch 30/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0104 - acc: 0.9972 - val_loss: 0.2107 - val_acc: 0.9329\n",
      "Epoch 31/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0111 - acc: 0.9966 - val_loss: 0.2775 - val_acc: 0.9204\n",
      "Epoch 32/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0099 - acc: 0.9971 - val_loss: 0.2090 - val_acc: 0.9442\n",
      "Epoch 33/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0104 - acc: 0.9968 - val_loss: 0.1610 - val_acc: 0.9553\n",
      "Epoch 34/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0093 - acc: 0.9973 - val_loss: 0.1806 - val_acc: 0.9467\n",
      "Epoch 35/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0096 - acc: 0.9968 - val_loss: 0.2143 - val_acc: 0.9406\n",
      "Epoch 36/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0100 - acc: 0.9971 - val_loss: 0.2052 - val_acc: 0.9426\n",
      "Epoch 37/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0097 - acc: 0.9972 - val_loss: 0.1167 - val_acc: 0.9669\n",
      "Epoch 38/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0098 - acc: 0.9968 - val_loss: 0.5114 - val_acc: 0.8776\n",
      "Epoch 39/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0087 - acc: 0.9974 - val_loss: 0.1868 - val_acc: 0.9481\n",
      "Epoch 40/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0082 - acc: 0.9975 - val_loss: 0.2094 - val_acc: 0.9506\n",
      "Epoch 41/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0089 - acc: 0.9971 - val_loss: 0.1623 - val_acc: 0.9649\n",
      "Epoch 42/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0112 - acc: 0.9963 - val_loss: 0.1934 - val_acc: 0.9483\n",
      "Epoch 43/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0110 - acc: 0.9966 - val_loss: 0.3182 - val_acc: 0.9100\n",
      "Epoch 44/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0083 - acc: 0.9973 - val_loss: 0.2587 - val_acc: 0.9365\n",
      "Epoch 45/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0079 - acc: 0.9976 - val_loss: 0.2735 - val_acc: 0.9274\n",
      "Epoch 46/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0078 - acc: 0.9975 - val_loss: 0.1266 - val_acc: 0.9646\n",
      "Epoch 47/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0083 - acc: 0.9973 - val_loss: 0.1787 - val_acc: 0.9621\n",
      "Epoch 48/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0075 - acc: 0.9979 - val_loss: 0.2028 - val_acc: 0.9497\n",
      "Epoch 49/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0081 - acc: 0.9975 - val_loss: 0.1858 - val_acc: 0.9587\n",
      "Epoch 50/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0059 - acc: 0.9984 - val_loss: 0.1993 - val_acc: 0.9599\n",
      "Epoch 51/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0064 - acc: 0.9980 - val_loss: 0.1816 - val_acc: 0.9533\n",
      "Epoch 52/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0075 - acc: 0.9978 - val_loss: 0.1905 - val_acc: 0.9417\n",
      "Epoch 53/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0057 - acc: 0.9983 - val_loss: 0.1356 - val_acc: 0.9669\n",
      "Epoch 54/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0078 - acc: 0.9979 - val_loss: 0.1588 - val_acc: 0.9605\n",
      "Epoch 55/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0072 - acc: 0.9977 - val_loss: 0.1490 - val_acc: 0.9637\n",
      "Epoch 56/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0061 - acc: 0.9979 - val_loss: 0.1509 - val_acc: 0.9705\n",
      "Epoch 57/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0078 - acc: 0.9976 - val_loss: 0.1112 - val_acc: 0.9746\n",
      "Epoch 58/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0072 - acc: 0.9978 - val_loss: 0.1544 - val_acc: 0.9599\n",
      "Epoch 59/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0070 - acc: 0.9978 - val_loss: 0.1605 - val_acc: 0.9644\n",
      "Epoch 60/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0063 - acc: 0.9981 - val_loss: 0.1615 - val_acc: 0.9617\n",
      "Epoch 61/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0089 - acc: 0.9972 - val_loss: 0.1399 - val_acc: 0.9676\n",
      "Epoch 62/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0076 - acc: 0.9973 - val_loss: 0.2920 - val_acc: 0.9286\n",
      "Epoch 63/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0092 - acc: 0.9968 - val_loss: 0.1668 - val_acc: 0.9635\n",
      "Epoch 64/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0089 - acc: 0.9968 - val_loss: 0.2185 - val_acc: 0.9488\n",
      "Epoch 65/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0060 - acc: 0.9980 - val_loss: 0.1737 - val_acc: 0.9633\n",
      "Epoch 66/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0057 - acc: 0.9982 - val_loss: 0.2050 - val_acc: 0.9456\n",
      "Epoch 67/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0054 - acc: 0.9982 - val_loss: 0.2165 - val_acc: 0.9438\n",
      "Epoch 68/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0076 - acc: 0.9978 - val_loss: 0.2641 - val_acc: 0.9358\n",
      "Epoch 69/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0068 - acc: 0.9980 - val_loss: 0.1947 - val_acc: 0.9497\n",
      "Epoch 70/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0073 - acc: 0.9976 - val_loss: 0.3060 - val_acc: 0.9320\n",
      "Epoch 71/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0070 - acc: 0.9977 - val_loss: 0.2086 - val_acc: 0.9492\n",
      "Epoch 72/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0054 - acc: 0.9983 - val_loss: 0.1717 - val_acc: 0.9653\n",
      "Epoch 73/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0059 - acc: 0.9980 - val_loss: 0.1313 - val_acc: 0.9646\n",
      "Epoch 74/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0058 - acc: 0.9981 - val_loss: 0.2394 - val_acc: 0.9372\n",
      "Epoch 75/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0064 - acc: 0.9980 - val_loss: 0.1727 - val_acc: 0.9612\n",
      "Epoch 76/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0060 - acc: 0.9982 - val_loss: 0.1461 - val_acc: 0.9660\n",
      "Epoch 77/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0060 - acc: 0.9981 - val_loss: 0.1663 - val_acc: 0.9585\n",
      "Epoch 78/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0053 - acc: 0.9984 - val_loss: 0.1593 - val_acc: 0.9553\n",
      "Epoch 79/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0059 - acc: 0.9980 - val_loss: 0.1691 - val_acc: 0.9610\n",
      "Epoch 80/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0040 - acc: 0.9987 - val_loss: 0.1355 - val_acc: 0.9669\n",
      "Epoch 81/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0041 - acc: 0.9986 - val_loss: 0.1243 - val_acc: 0.9714\n",
      "Epoch 82/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0057 - acc: 0.9982 - val_loss: 0.2010 - val_acc: 0.9540\n",
      "Epoch 83/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0053 - acc: 0.9981 - val_loss: 0.2004 - val_acc: 0.9508\n",
      "Epoch 84/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0054 - acc: 0.9984 - val_loss: 0.1759 - val_acc: 0.9617\n",
      "Epoch 85/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0060 - acc: 0.9979 - val_loss: 0.1580 - val_acc: 0.9603\n",
      "Epoch 86/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0063 - acc: 0.9976 - val_loss: 0.1275 - val_acc: 0.9689\n",
      "Epoch 87/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0073 - acc: 0.9977 - val_loss: 0.1880 - val_acc: 0.9630\n",
      "Epoch 88/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0045 - acc: 0.9986 - val_loss: 0.1683 - val_acc: 0.9662\n",
      "Epoch 89/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0049 - acc: 0.9984 - val_loss: 0.1141 - val_acc: 0.9732\n",
      "Epoch 90/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0067 - acc: 0.9978 - val_loss: 0.1477 - val_acc: 0.9578\n",
      "Epoch 91/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0058 - acc: 0.9981 - val_loss: 0.1224 - val_acc: 0.9723\n",
      "Epoch 92/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0039 - acc: 0.9987 - val_loss: 0.1573 - val_acc: 0.9601\n",
      "Epoch 93/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0057 - acc: 0.9982 - val_loss: 0.1393 - val_acc: 0.9667\n",
      "Epoch 94/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0054 - acc: 0.9983 - val_loss: 0.2602 - val_acc: 0.9392\n",
      "Epoch 95/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0041 - acc: 0.9984 - val_loss: 0.1103 - val_acc: 0.9719\n",
      "Epoch 96/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0059 - acc: 0.9979 - val_loss: 0.1691 - val_acc: 0.9596\n",
      "Epoch 97/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0058 - acc: 0.9981 - val_loss: 0.2303 - val_acc: 0.9533\n",
      "Epoch 98/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0053 - acc: 0.9982 - val_loss: 0.1979 - val_acc: 0.9528\n",
      "Epoch 99/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0046 - acc: 0.9983 - val_loss: 0.1484 - val_acc: 0.9621\n",
      "Epoch 100/100\n",
      "34799/34799 [==============================] - 14s - loss: 0.0064 - acc: 0.9982 - val_loss: 0.2565 - val_acc: 0.9410\n"
     ]
    }
   ],
   "source": [
    "model = cnn_model(flag_BN=True)\n",
    "# Compile and train the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512, nb_epoch=100,\n",
    "                    verbose=1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12512/12630 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2789941485898948, 0.94259699136608666]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('models/CNN_BN.ckpt')\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with Batch Normalization and Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#data augmentation\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def get_datagen():\n",
    "\n",
    "\n",
    "    datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                             featurewise_std_normalization=False,\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             zoom_range=0.2,\n",
    "                             shear_range=0.1,\n",
    "                             rotation_range=10.)\n",
    "\n",
    "    return datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_34 (Conv2D)           (None, 32, 32, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 43)                44075     \n",
      "=================================================================\n",
      "Total params: 2,239,915\n",
      "Trainable params: 2,237,419\n",
      "Non-trainable params: 2,496\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "27839/27839 [==============================] - 5569s - loss: 0.0534 - acc: 0.9832 - val_loss: 0.0752 - val_acc: 0.9839\n"
     ]
    }
   ],
   "source": [
    "model = cnn_model(flag_BN=True)\n",
    "# Compile and train the model\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train again\n",
    "epochs = 1\n",
    "datagen = get_datagen()\n",
    "history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=512),\n",
    "                    steps_per_epoch=X_train.shape[0],\n",
    "                              \n",
    "                    epochs=100,verbose=1,\n",
    "                    validation_data=(X_val, y_val)\n",
    "                    #callbacks=[LearningRateScheduler(lr_schedule),\n",
    "                    #           ModelCheckpoint('model.h5', save_best_only=True)]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with Batch Normalization and Spatial Transformer, No Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STN CNN Model with Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.models.Sequential object at 0x7faf4a37f780>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "spatial_transformer_8 (Spati (None, 32, 32, 1)         14896     \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 32, 32, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 43)                44075     \n",
      "=================================================================\n",
      "Total params: 2,254,811\n",
      "Trainable params: 2,252,315\n",
      "Non-trainable params: 2,496\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34799 samples, validate on 4410 samples\n",
      "Epoch 1/100\n",
      "34799/34799 [==============================] - 17s - loss: 2.3574 - acc: 0.3822 - val_loss: 3.7336 - val_acc: 0.0476\n",
      "Epoch 2/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.5972 - acc: 0.8214 - val_loss: 3.7187 - val_acc: 0.1150\n",
      "Epoch 3/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.2590 - acc: 0.9248 - val_loss: 3.9177 - val_acc: 0.1032\n",
      "Epoch 4/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.1536 - acc: 0.9575 - val_loss: 2.7077 - val_acc: 0.2912\n",
      "Epoch 5/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.1095 - acc: 0.9706 - val_loss: 1.5999 - val_acc: 0.5544\n",
      "Epoch 6/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0788 - acc: 0.9777 - val_loss: 1.2531 - val_acc: 0.6392\n",
      "Epoch 7/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0597 - acc: 0.9840 - val_loss: 0.7405 - val_acc: 0.7866\n",
      "Epoch 8/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0493 - acc: 0.9867 - val_loss: 0.3905 - val_acc: 0.8812\n",
      "Epoch 9/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0400 - acc: 0.9890 - val_loss: 0.2375 - val_acc: 0.9224\n",
      "Epoch 10/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0354 - acc: 0.9902 - val_loss: 0.1990 - val_acc: 0.9392\n",
      "Epoch 11/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0288 - acc: 0.9925 - val_loss: 0.1882 - val_acc: 0.9444\n",
      "Epoch 12/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0266 - acc: 0.9933 - val_loss: 0.2467 - val_acc: 0.9290\n",
      "Epoch 13/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0225 - acc: 0.9934 - val_loss: 0.4191 - val_acc: 0.8732\n",
      "Epoch 14/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0190 - acc: 0.9949 - val_loss: 0.3069 - val_acc: 0.9120\n",
      "Epoch 15/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0172 - acc: 0.9955 - val_loss: 0.2276 - val_acc: 0.9358\n",
      "Epoch 16/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0135 - acc: 0.9968 - val_loss: 0.1889 - val_acc: 0.9442\n",
      "Epoch 17/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0131 - acc: 0.9964 - val_loss: 0.2132 - val_acc: 0.9383\n",
      "Epoch 18/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0136 - acc: 0.9961 - val_loss: 0.3416 - val_acc: 0.9138\n",
      "Epoch 19/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0120 - acc: 0.9968 - val_loss: 0.2995 - val_acc: 0.9170\n",
      "Epoch 20/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0119 - acc: 0.9966 - val_loss: 0.3837 - val_acc: 0.8812\n",
      "Epoch 21/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0102 - acc: 0.9972 - val_loss: 0.1968 - val_acc: 0.9395\n",
      "Epoch 22/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0091 - acc: 0.9974 - val_loss: 0.1499 - val_acc: 0.9580\n",
      "Epoch 23/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0089 - acc: 0.9977 - val_loss: 0.1243 - val_acc: 0.9655\n",
      "Epoch 24/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0076 - acc: 0.9980 - val_loss: 0.1241 - val_acc: 0.9637\n",
      "Epoch 25/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0062 - acc: 0.9987 - val_loss: 0.1219 - val_acc: 0.9653\n",
      "Epoch 26/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0068 - acc: 0.9982 - val_loss: 0.1221 - val_acc: 0.9689\n",
      "Epoch 27/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0073 - acc: 0.9978 - val_loss: 0.2322 - val_acc: 0.9397\n",
      "Epoch 28/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0080 - acc: 0.9976 - val_loss: 0.1515 - val_acc: 0.9567\n",
      "Epoch 29/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0071 - acc: 0.9982 - val_loss: 0.1778 - val_acc: 0.9429\n",
      "Epoch 30/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0069 - acc: 0.9983 - val_loss: 0.2493 - val_acc: 0.9243\n",
      "Epoch 31/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0073 - acc: 0.9980 - val_loss: 0.1847 - val_acc: 0.9424\n",
      "Epoch 32/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0063 - acc: 0.9983 - val_loss: 0.1492 - val_acc: 0.9565\n",
      "Epoch 33/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0055 - acc: 0.9986 - val_loss: 0.1422 - val_acc: 0.9605\n",
      "Epoch 34/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0050 - acc: 0.9986 - val_loss: 0.1120 - val_acc: 0.9644\n",
      "Epoch 35/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0068 - acc: 0.9979 - val_loss: 0.1493 - val_acc: 0.9610\n",
      "Epoch 36/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0061 - acc: 0.9982 - val_loss: 0.2225 - val_acc: 0.9347\n",
      "Epoch 37/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0043 - acc: 0.9986 - val_loss: 0.1339 - val_acc: 0.9601\n",
      "Epoch 38/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0035 - acc: 0.9989 - val_loss: 0.1284 - val_acc: 0.9683\n",
      "Epoch 39/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0045 - acc: 0.9988 - val_loss: 0.1390 - val_acc: 0.9646\n",
      "Epoch 40/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0039 - acc: 0.9988 - val_loss: 0.1843 - val_acc: 0.9567\n",
      "Epoch 41/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0037 - acc: 0.9990 - val_loss: 0.1512 - val_acc: 0.9626\n",
      "Epoch 42/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0032 - acc: 0.9990 - val_loss: 0.1040 - val_acc: 0.9744\n",
      "Epoch 43/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0041 - acc: 0.9988 - val_loss: 0.1328 - val_acc: 0.9667\n",
      "Epoch 44/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0048 - acc: 0.9987 - val_loss: 0.1149 - val_acc: 0.9669\n",
      "Epoch 45/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0052 - acc: 0.9984 - val_loss: 0.2312 - val_acc: 0.9385\n",
      "Epoch 46/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0050 - acc: 0.9985 - val_loss: 0.1837 - val_acc: 0.9558\n",
      "Epoch 47/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0046 - acc: 0.9988 - val_loss: 0.3949 - val_acc: 0.8955\n",
      "Epoch 48/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0044 - acc: 0.9988 - val_loss: 0.2165 - val_acc: 0.9540\n",
      "Epoch 49/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0054 - acc: 0.9982 - val_loss: 0.1315 - val_acc: 0.9680\n",
      "Epoch 50/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0053 - acc: 0.9986 - val_loss: 0.1239 - val_acc: 0.9680\n",
      "Epoch 51/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0047 - acc: 0.9985 - val_loss: 0.1991 - val_acc: 0.9447\n",
      "Epoch 52/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0048 - acc: 0.9985 - val_loss: 0.1387 - val_acc: 0.9553\n",
      "Epoch 53/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0049 - acc: 0.9985 - val_loss: 0.1180 - val_acc: 0.9669\n",
      "Epoch 54/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0039 - acc: 0.9988 - val_loss: 0.1132 - val_acc: 0.9644\n",
      "Epoch 55/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0054 - acc: 0.9985 - val_loss: 0.1633 - val_acc: 0.9619\n",
      "Epoch 56/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0046 - acc: 0.9985 - val_loss: 0.1266 - val_acc: 0.9712\n",
      "Epoch 57/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0030 - acc: 0.9991 - val_loss: 0.1545 - val_acc: 0.9615\n",
      "Epoch 58/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0040 - acc: 0.9988 - val_loss: 0.1290 - val_acc: 0.9664\n",
      "Epoch 59/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0039 - acc: 0.9988 - val_loss: 0.3458 - val_acc: 0.9075\n",
      "Epoch 60/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0031 - acc: 0.9992 - val_loss: 0.1792 - val_acc: 0.9546\n",
      "Epoch 61/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0056 - acc: 0.9979 - val_loss: 0.1588 - val_acc: 0.9590\n",
      "Epoch 62/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0034 - acc: 0.9990 - val_loss: 0.1678 - val_acc: 0.9644\n",
      "Epoch 63/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0033 - acc: 0.9989 - val_loss: 0.1707 - val_acc: 0.9587\n",
      "Epoch 64/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0040 - acc: 0.9987 - val_loss: 0.1309 - val_acc: 0.9664\n",
      "Epoch 65/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0044 - acc: 0.9985 - val_loss: 0.2570 - val_acc: 0.9406\n",
      "Epoch 66/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0060 - acc: 0.9980 - val_loss: 0.2094 - val_acc: 0.9467\n",
      "Epoch 67/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0080 - acc: 0.9975 - val_loss: 0.3029 - val_acc: 0.9254\n",
      "Epoch 68/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0065 - acc: 0.9980 - val_loss: 0.1923 - val_acc: 0.9603\n",
      "Epoch 69/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0052 - acc: 0.9984 - val_loss: 0.1998 - val_acc: 0.9531\n",
      "Epoch 70/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0044 - acc: 0.9986 - val_loss: 0.1537 - val_acc: 0.9717\n",
      "Epoch 71/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0034 - acc: 0.9990 - val_loss: 0.1660 - val_acc: 0.9671\n",
      "Epoch 72/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0020 - acc: 0.9995 - val_loss: 0.1498 - val_acc: 0.9676\n",
      "Epoch 73/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0025 - acc: 0.9992 - val_loss: 0.1472 - val_acc: 0.9655\n",
      "Epoch 74/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0039 - acc: 0.9986 - val_loss: 0.2007 - val_acc: 0.9556\n",
      "Epoch 75/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0038 - acc: 0.9989 - val_loss: 0.1410 - val_acc: 0.9748\n",
      "Epoch 76/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0058 - acc: 0.9981 - val_loss: 0.1833 - val_acc: 0.9637\n",
      "Epoch 77/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0056 - acc: 0.9979 - val_loss: 0.1155 - val_acc: 0.9678\n",
      "Epoch 78/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0039 - acc: 0.9986 - val_loss: 0.3870 - val_acc: 0.8984\n",
      "Epoch 79/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0036 - acc: 0.9988 - val_loss: 0.2519 - val_acc: 0.9279\n",
      "Epoch 80/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0037 - acc: 0.9989 - val_loss: 0.1863 - val_acc: 0.9501\n",
      "Epoch 81/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0027 - acc: 0.9992 - val_loss: 0.1572 - val_acc: 0.9574\n",
      "Epoch 82/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0015 - acc: 0.9995 - val_loss: 0.1206 - val_acc: 0.9701\n",
      "Epoch 83/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0025 - acc: 0.9993 - val_loss: 0.1704 - val_acc: 0.9551\n",
      "Epoch 84/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0026 - acc: 0.9991 - val_loss: 0.1128 - val_acc: 0.9678\n",
      "Epoch 85/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0022 - acc: 0.9994 - val_loss: 0.0870 - val_acc: 0.9748\n",
      "Epoch 86/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0020 - acc: 0.9995 - val_loss: 0.1080 - val_acc: 0.9714\n",
      "Epoch 87/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0026 - acc: 0.9991 - val_loss: 0.1464 - val_acc: 0.9615\n",
      "Epoch 88/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0030 - acc: 0.9989 - val_loss: 0.1498 - val_acc: 0.9592\n",
      "Epoch 89/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0029 - acc: 0.9991 - val_loss: 0.0906 - val_acc: 0.9787\n",
      "Epoch 90/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0027 - acc: 0.9992 - val_loss: 0.1461 - val_acc: 0.9685\n",
      "Epoch 91/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0028 - acc: 0.9991 - val_loss: 0.1836 - val_acc: 0.9610\n",
      "Epoch 92/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0013 - acc: 0.9996 - val_loss: 0.1521 - val_acc: 0.9680\n",
      "Epoch 93/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0036 - acc: 0.9988 - val_loss: 0.1579 - val_acc: 0.9655\n",
      "Epoch 94/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0028 - acc: 0.9992 - val_loss: 0.1382 - val_acc: 0.9757\n",
      "Epoch 95/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0021 - acc: 0.9994 - val_loss: 0.1604 - val_acc: 0.9660\n",
      "Epoch 96/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0036 - acc: 0.9989 - val_loss: 0.4242 - val_acc: 0.9002\n",
      "Epoch 97/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0056 - acc: 0.9983 - val_loss: 0.1410 - val_acc: 0.9703\n",
      "Epoch 98/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0053 - acc: 0.9983 - val_loss: 0.1814 - val_acc: 0.9594\n",
      "Epoch 99/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0056 - acc: 0.9983 - val_loss: 0.1497 - val_acc: 0.9658\n",
      "Epoch 100/100\n",
      "34799/34799 [==============================] - 16s - loss: 0.0025 - acc: 0.9990 - val_loss: 0.1737 - val_acc: 0.9610\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = cnn_model(flag_BN=True,flag_STN=True)\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512, nb_epoch=100\n",
    "                    ,\n",
    "                    verbose=1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12608/12630 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.18702008974689474, 0.95566112438271378]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('models/STN_BN_CNN.ckpt')\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with STN, Batch Normalization and Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.models.Sequential object at 0x7faf49030080>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "spatial_transformer_11 (Spat (None, 32, 32, 1)         14896     \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 32, 32, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_70 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_71 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_72 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_72 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_29 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 43)                44075     \n",
      "=================================================================\n",
      "Total params: 2,254,811\n",
      "Trainable params: 2,252,315\n",
      "Non-trainable params: 2,496\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "34799/34799 [==============================] - 8747s - loss: 0.0677 - acc: 0.9806 - val_loss: 0.0849 - val_acc: 0.9868\n",
      "Epoch 2/100\n",
      "34799/34799 [==============================] - 8764s - loss: 0.0282 - acc: 0.9919 - val_loss: 0.0689 - val_acc: 0.9880\n",
      "Epoch 3/100\n",
      "34799/34799 [==============================] - 8764s - loss: 0.0233 - acc: 0.9933 - val_loss: 0.0683 - val_acc: 0.9882\n",
      "Epoch 4/100\n",
      "11545/34799 [========>.....................] - ETA: 5856s - loss: 0.0214 - acc: 0.9939"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-a5afccb7885c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                     \u001b[0;31m#callbacks=[LearningRateScheduler(lr_schedule),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0;31m#           ModelCheckpoint('model.h5', save_best_only=True)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[1;32m   1119\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2040\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2041\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2042\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1760\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model = cnn_model(flag_BN=True,flag_STN=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 5\n",
    "datagen = get_datagen()\n",
    "history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=512),\n",
    "                    steps_per_epoch=X_train.shape[0],\n",
    "                    epochs=100,verbose=1,\n",
    "                    validation_data=(X_val, y_val)\n",
    "                    #callbacks=[LearningRateScheduler(lr_schedule),\n",
    "                    #           ModelCheckpoint('model.h5', save_best_only=True)]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('models/STN_BN_DA_CNN.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12608/12630 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.056696130254824374, 0.98875692794932701]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34799\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTHER STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LearningRateScheduler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-67e8f541658c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m                             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                             callbacks=[LearningRateScheduler(lr_schedule),\n\u001b[0m\u001b[1;32m     60\u001b[0m                                        ModelCheckpoint('model.h5',save_best_only=True)]\n\u001b[1;32m     61\u001b[0m                            )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LearningRateScheduler' is not defined"
     ]
    }
   ],
   "source": [
    "#Keras tutorial \n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "\n",
    "\n",
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=(32,32,3),\n",
    "                     activation='relu'))\n",
    "    #model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    #model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    #model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(43, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(featurewise_center=False, \n",
    "                            featurewise_std_normalization=False, \n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            zoom_range=0.2,\n",
    "                            shear_range=0.1,\n",
    "                            rotation_range=10.,)\n",
    "\n",
    "model = cnn_model()\n",
    "# let's train the model using SGD + momentum (how original).\n",
    "lr = 0.01\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=sgd,\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return lr*(0.1**int(epoch/10))\n",
    "\n",
    "nb_epoch = 30\n",
    "model.fit_generator(datagen.flow(X_train, y_train  , batch_size=128),\n",
    "                            steps_per_epoch=X_train.shape[0],\n",
    "                            epochs=nb_epoch,\n",
    "                            validation_data=(X_val, y_val),\n",
    "                            callbacks=[LearningRateScheduler(lr_schedule),\n",
    "                                       ModelCheckpoint('model.h5',save_best_only=True)]\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout,Convolution2D,Conv2D,MaxPooling2D,Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# number of classes\n",
    "nb_classes = 43\n",
    "# input image dimensions\n",
    "img_rows, img_cols, img_ch = 32, 32, 3\n",
    "# number of convolutional filters to use\n",
    "nb_filter1 = 32\n",
    "nb_filter2 = 64\n",
    "nb_filter3 = 128\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "pool_strides = (1,1)\n",
    "# convolution kernel size\n",
    "kernel_size = (5, 5)\n",
    "# number of hidden units in the first fully connected layer\n",
    "nb_fc1=512\n",
    "nb_fc2=128\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Convolution / Max / Pooling / Dropout\n",
    "\n",
    "model.add(Conv2D(32, (5, 5), border_mode='same', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#model.add(Conv2D(32, (5, 5), border_mode='same', input_shape=(32, 32, 3)))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "#model.add(Conv2D(nb_filter1, kernel_size, strides=pool_strides, padding='same', data_format=\"channels_last\", \n",
    "#                    input_shape=(img_rows,img_cols,img_ch),name='conv1'))\n",
    "#model.add(MaxPooling2D(pool_size=pool_size,strides=pool_strides,name='maxpool1'))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "#model.add(Activation('relu',name='relu1'))\n",
    "model.add(Conv2D(nb_filter2, kernel_size,strides=pool_strides,padding='same',name='conv2'))\n",
    "model.add(Activation('relu',name='relu2'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size,strides=None,name='maxpool2'))\n",
    "model.add(Conv2D(nb_filter3, kernel_size,padding='same',strides=pool_strides, \n",
    "                        name='conv3'))\n",
    "model.add(Activation('relu',name='relu3'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size,strides=None,name='maxpool3'))\n",
    "model.add(Flatten(name='flatten'))\n",
    "model.add(Dropout(0.5,name='dropout1'))\n",
    "model.add(Dense(nb_fc1, name='hidden1'))\n",
    "model.add(Activation('relu',name='relu4'))\n",
    "model.add(Dropout(0.5,name='dropout2'))\n",
    "model.add(Dense(nb_fc2,  name='hidden2'))\n",
    "model.add(Activation('relu',name='relu5'))\n",
    "model.add(Dense(nb_classes, name='output'))\n",
    "model.add(Activation('softmax',name='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "nb_epoch = 10\n",
    "batch_size=128\n",
    "\n",
    "\n",
    "\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=adam,\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "                    verbose=2, validation_data=(X_val, Y_val))\n",
    "\n",
    "\n",
    "\n",
    "# STOP: Do not change the tests below. Your implementation should pass these tests.\n",
    "assert(history.history['val_acc'][-1] > 0.9), \"The validation accuracy is: %.3f\" % history.history['val_acc'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
